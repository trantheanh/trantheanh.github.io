---
title: "[ML â€“ 17] Neural Net Regularization with Drop-Out"
date: 2017-06-26
layout: post
comments: true
mathjax: true
---

ChÃ o cÃ¡c báº¡n, ráº¥t vui Ä‘Æ°á»£c gáº·p láº¡i cÃ¡c báº¡n trong bÃ i viáº¿t nÃ y. HÃ´m nay chÃºng ta sáº½ tÃ¬m hiá»ƒu vá» má»™t kÄ© thuáº­t Regularization cho ANN Ä‘Æ°á»£c gá»i lÃ  Drop-Out. Thay vÃ¬ Ä‘i vÃ o tÃ¬m hiá»ƒu â€œÄ‘áº¡o lÃ½â€ Ä‘áº±ng sau kÄ© thuáº­t nÃ y hay phÃ¢n phá»‘i xÃ¡c suáº¥t Ä‘áº±ng sau nÃ³, tÃ´i sáº½ giáº£i thÃ­ch má»™t cÃ¡ch trá»±c quan Ä‘á»ƒ cÃ¡c báº¡n dá»… hiá»ƒu, dá»… náº¯m báº¯t vÃ  mÆ°á»ng tÆ°á»£ng Ä‘Æ°á»£c Ã½ nghÄ©a cá»§a nÃ³.

## 1. Drop-Out lÃ  gÃ¬:

NhÆ° ta Ä‘Ã£ biáº¿t overfitting lÃ  má»™t váº¥n náº¡n Ä‘á»‘i vá»›i Machine Learning, Ä‘áº·c biá»‡t lÃ  trong máº¡ng NN. Khi muá»‘n cho mÃ´ hÃ¬nh trá»Ÿ nÃªn phá»©c táº¡p hÆ¡n, ta thÆ°á»ng tÄƒng sá»‘ lÆ°á»£ng layer vÃ  sá»‘ lÆ°á»£ng unit cá»§a má»—i layer thay vÃ¬ tÄƒng báº­c cá»§a feature nhÆ° trÆ°á»›c Ä‘Ã¢y Ä‘Ã£ Ä‘á» cáº­p. NhÆ°ng khi mÃ´ hÃ¬nh phá»©c táº¡p hÆ¡n, overfitting báº¯t Ä‘áº§u xuáº¥t hiá»‡n, vÃ¬ sá»‘ lÆ°á»£ng tham sá»‘ trong máº¡ng NN nhiá»u vÃ  cÃ³ â€œÄ‘á»™ sÃ¢uâ€ khÃ¡c nhau, vÃ¬ váº­y khi Ã¡p dá»¥ng chung ğº cho táº¥t cáº£ cÃ¡c tham sá»‘ sáº½ yÃªu cáº§u sá»‘ láº§n training lá»›n Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c ğº phÃ¹ há»£p. CÃ³ má»™t kÄ© thuáº­t dÃ nh riÃªng cho máº¡ng NN vÃ  khÃ¡ Ä‘Æ¡n giáº£n, Ä‘Ã³ lÃ  Drop-out (má»™t kÄ© thuáº­t khÃ¡c Ä‘Æ°á»£c biáº¿t Ä‘áº¿n tÆ°Æ¡ng tá»± lÃ  Drop-Connect).
Drop-out lÃ  má»™t kÄ© thuáº­t Regularization Ä‘á»ƒ chá»‘ng láº¡i váº¥n Ä‘á» overfitting. CÃ¡ch Drop-out thá»±c hiá»‡n lÃ  xoÃ¡ bá» má»™t sá»‘ unit trong cÃ¡c step training á»©ng vá»›i má»™t giÃ¡ trá»‹ xÃ¡c suáº¥t p cho trÆ°á»›c. 

<img src="/assets/content_images/ml17-01.png" alt = "" width = "100%">

## 2. Drop-Out hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o:


 Drop-Out Ä‘Æ°á»£c Ã¡p dá»¥ng trÃªn má»™t layer cá»§a máº¡ng NN vá»›i má»™t xÃ¡c suáº¥t p cho trÆ°á»›c (ta cÃ³ thá»ƒ sá»­ dá»¥ng nhiá»u Drop-Out khÃ¡c nhau cho nhá»¯ng layer khÃ¡c nhau, nhÆ°ng trÃªn 1 layer sáº½ chá»‰ cÃ³ 1 Drop-Out).
 Táº¡i má»—i step trong quÃ¡ trÃ¬nh training, khi thá»±c hiá»‡n Forward Propagation (Lan truyá»n xuÃ´i) Ä‘áº¿n layer sá»­ dá»¥ng Drop-Out, thay vÃ¬ tÃ­nh toÃ¡n táº¥t cáº£ unit cÃ³ trÃªn layer, táº¡i má»—i unit ta â€œgieo xÃºc xáº¯câ€ xem unit Ä‘Ã³ cÃ³ Ä‘Æ°á»£c tÃ­nh hay khÃ´ng dá»±a trÃªn xÃ¡c suáº¥t p. Vá»›i nhá»¯ng unit Ä‘Æ°á»£c tÃ­nh, ta tÃ­nh toÃ¡n bÃ¬nh thÆ°á»ng cÃ²n vá»›i nhá»¯ng unit khÃ´ng Ä‘Æ°á»£c tÃ­nh giÃ¡ trá»‹ táº¡i unit Ä‘Ã³ = 0.
 Khi thá»±c hiá»‡n tÃ­nh toÃ¡n trÃªn máº¡ng NN trong quÃ¡ trÃ¬nh test (sá»­ dá»¥ng máº¡ng NN Ä‘á»ƒ dá»± Ä‘oÃ¡n) thay vÃ¬ lÃ m nhÆ° trÃªn, ta thá»±c hiá»‡n tÃ­nh toÃ¡n trÃªn táº¥t cáº£ cÃ¡c unit nhÆ°ng trá»ng sá»‘ trÃªn má»—i connect Ä‘áº¿n cÃ¡c unit cá»§a layer Ä‘Æ°á»£c Ã¡p dá»¥ng Drop-Out Ä‘Æ°á»£c thay tháº¿ báº±ng giÃ¡ trá»‹ cá»§a trá»ng sá»‘ Ä‘Ã³ vá»›i xÃ¡c suáº¥t p hay \\(Î¸ := Î¸ * p\\)

## 3. Táº¡i sao Drop-Out hiá»‡u quáº£:

Äá»‘i vá»›i máº¡ng NN, khÃ´ng giá»‘ng nhÆ° nhá»¯ng kÄ© thuáº­t khÃ¡c nhÆ° **Linear Regression** hay **Logistic Regression** lÃ  Ä‘áº©y báº­c cá»§a feature lÃªn mÃ  ta tÄƒng sá»‘ lÆ°á»£ng hidden layer vÃ  sá»‘ lÆ°á»£ng unit trong cÃ¡c layer lÃªn. NhÆ°ng Ä‘á»‘i khi do viá»‡c thÃªm vÃ o quÃ¡ nhiá»u hidden layer cÅ©ng nhÆ° unit khiáº¿n cho mÃ´ hÃ¬nh phá»©c táº¡p hÆ¡n má»©c cáº§n thiáº¿t vÃ  khiáº¿n chÃºng bá»‹ overfitting. ChÃ­nh vÃ¬ váº­y Ä‘á»ƒ trÃ¡nh bá»‹ overfitting trong trÆ°á»ng há»£p nÃ y, ta cáº§n pháº£i giáº£n lÆ°á»£c máº¡ng NN hiá»‡n cÃ³. Khi Ã¡p dá»¥ng **Drop-Out** vÃ o 1 layer nÃ o Ä‘Ã³, thÃ¬ thá»±c táº¿ táº¡i má»—i training step máº¡ng NN cá»§a ta chá»‰ cÃ²n 1 pháº§n: 

<iframe width="560" height="315" src="https://www.youtube.com/embed/XkNjYME2dPg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

Giáº£ sá»­ layer cá»§a ta cÃ³ 4 unit (nhÆ° trong clip minh hoáº¡), vÃ  xÃ¡c suáº¥t p = 0.8 -> khi Ä‘Ã³ xÃ¡c suáº¥t sá»­ dá»¥ng sá»‘ lÆ°á»£ng unit cá»§a layer sáº½ nhÆ° sau:

* Sá»­ dá»¥ng 0 unit cá»§a layer: \\(= 1 * (1-p)^4 * p^0 = 0.24 = 0.0016 \\)(VÃ¬ xÃ¡c suáº¥t Ä‘á»ƒ má»—i unit khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng lÃ  \\(1-p\\) nÃªn Ä‘á»ƒ cáº£ 4 unit khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng thÃ¬ xÃ¡c suáº¥t pháº£i lÃ  \\((1-p)^4\\) vÃ  chá»‰ cÃ³ \\(C_4^0\\) = 1 kháº£ nÄƒng chá»n ra 0 unit Ä‘Æ°á»£c sá»­ dá»¥ng)
* Sá»­ dá»¥ng 1 unit cá»§a layer: \\(= 4 * p^1 * (1-p)^3 = 4 * 0.8 * 0.23 = 0.0256 \\) (VÃ¬ xÃ¡c suáº¥t Ä‘á»ƒ má»—i unit khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng lÃ  \\(1-p\\) nÃªn Ä‘á»ƒ 3 unit khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng thÃ¬ xÃ¡c suáº¥t pháº£i lÃ  \\((1-p)^3\\) vÃ  cÃ³ thÃªm 1 unit Ä‘Æ°á»£c sá»­ dá»¥ng vá»›i xÃ¡c suáº¥t \\(p\\), bÃªn cáº¡nh Ä‘Ã³ cÃ³ tá»›i \\(C _{4} ^{1} = 4\\) unit cÃ³ thá»ƒ Ä‘Æ°á»£c chá»n Ä‘á»ƒ sá»­ dá»¥ng)
* TÆ°Æ¡ng tá»± khi sá»­ dá»¥ng 2 unit cá»§a layer: \\(= 6 * p^2 * (1-p)^2 = 6 * 0.82 * 0.2 2 = 0.1536\\) (cÃ³ \\(C_4^2 = 6\\) cÃ¡ch Ä‘á»ƒ lá»±a chá»n 2 unit Ä‘á»ƒ sá»­ dá»¥ng trong 4 unit cá»§a layer)
* Khi sá»­ dá»¥ng 3 unit cá»§a layer: \\(= 4 * p^3 * (1-p)^1 = 4 * 0.83 * 0.2 = 0.4096 \\) (cÃ³ \\(C_4^3 = 4\\) cÃ¡ch Ä‘á»ƒ lá»±a chá»n 3 unit Ä‘á»ƒ sá»­ dá»¥ng trong 4 unit cá»§a layer)
â€“ Khi sá»­ dá»¥ng 4 unit cá»§a layer: \\(= p^4 * (1-p)^0= 0.84= 0.4096\\) (chá»‰ cÃ³ \\(C_4^4 = 1\\) cÃ¡ch Ä‘á»ƒ lá»±a chá»n 4 unit Ä‘á»ƒ sá»­ dá»¥ng trong 4 unit cá»§a layer)
TÃ­nh trung bÃ¬nh ra ta cÃ³ sá»‘ lÆ°á»£ng unit layer sá»­ dá»¥ng khi Ã¡p dá»¥ng Drop-Out: 
\\[E(#unit) = 0 * 0.0016 + 1 * 0.0256 + 2 * 0.1536 + 3 * 0.4096 + 4 * 0.4096 = 3.2 = 4 * 0.8 = 4 * p\\]
 (Sá»‘ lÆ°á»£ng unit nhÃ¢n vá»›i xÃ¡c suáº¥t \\(p\\)). NghÄ©a lÃ  khi Ã¡p dá»¥ng **Drop-Out** layer cá»§a ta chá»‰ sá»­ dá»¥ng sá»‘ unit tÆ°Æ¡ng Ä‘Æ°Æ¡ng \\(3.2\\) báº±ng cÃ¡ch sá»­ dá»¥ng nhiá»u máº¡ng nhá» (vá»›i 0,1,2,3,4 unit trong layer nhÆ° mÃ´ táº£ á»Ÿ trÃªn)

Cuá»‘i cÃ¹ng, cÃ¡c báº¡n sáº½ tháº¯c máº¯c táº¡i sao khi sá»­ dá»¥ng máº¡ng NN Ä‘á»ƒ test ta láº¡i khÃ´ng â€œgieo xÃºc xáº¯câ€ nhÆ° khi training mÃ  láº¡i sá»­ dá»¥ng trá»ng sá»‘ cÃ³ giÃ¡ trá»‹ bá»‹ giáº£m Ä‘i theo xÃ¡c suáº¥t p. ÄÆ¡n giáº£n lÃ  vÃ¬ khi cÃ¡c unit Ä‘Æ°á»£c sá»­ dá»¥ng vá»›i xÃ¡c suáº¥t nhÆ° trÃªn, cÃ¡c trá»ng sá»‘ cÅ©ng Ä‘Æ°á»£c update vá»›i tá»‰ lá»‡ tÆ°Æ¡ng tá»±, nÃªn Ä‘á»ƒ thay vÃ¬ pháº£i tÃ­nh káº¿t quáº£ trÃªn táº¥t cÃ¡c máº¡ng con báº±ng cÃ¡ch â€œgieo xÃºc sáº¯câ€, ta thá»±c hiá»‡n approximate giÃ¡ trá»‹ trung bÃ¬nh cá»§a táº¥t cáº£ cÃ¡c máº¡ng con báº±ng cÃ¡ch scale \\(\theta\\) theo p.