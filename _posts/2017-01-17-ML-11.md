---
title: "[ML â€“ 11] Machine Learning Diagnostic 1/2"
date: 2017-01-17
layout: post
comments: true
mathjax: true
---

Xin chÃ o cÃ¡c báº¡n, ráº¥t vui Ä‘Æ°á»£c gáº·p láº¡i cÃ¡c báº¡n trong bÃ i viáº¿t thá»© 11 trong loáº¡t bÃ i vá» Machine Learning. Trong 10 bÃ i viáº¿t trÆ°á»›c chÃºng ta Ä‘Ã£ tÃ¬m hiá»ƒu Ä‘Æ°á»£c khÃ¡ nhiá»u kÄ© thuáº­t nhÆ° cÃ¡c giáº£i thuáº­t, mÃ´ hÃ¬nh, hay phÆ°Æ¡ng phÃ¡p xá»­ lÃ½ khi gáº·p váº¥n Ä‘á» vá» Underfitting vÃ  Overfitting. HÃ´m nay, ta sáº½ cÃ¹ng nhau tÃ¬m hiá»ƒu lÃ m tháº¿ nÃ o Ä‘á»ƒ xÃ¡c Ä‘á»‹nh mÃ´ hÃ¬nh hay giáº£i thuáº­t chÃºng ta Ä‘ang phÃ¡t triá»ƒn gáº·p pháº£i váº¥n Ä‘á» vÃ  cÃ¡ch giáº£i quyáº¿t chÃºng.

## 1. When debugging is necessary and what to try ?

Viá»‡c tá»‘i quan trá»ng sau khi cÃ i Ä‘áº·t mÃ´ hÃ¬nh, ta cáº§n pháº£i xÃ¡c Ä‘á»‹nh xem mÃ´ hÃ¬nh hay giáº£i thuáº­t Ä‘Ã³ cÃ³ váº¥n Ä‘á» khÃ´ng ? Vá»›i váº¥n Ä‘á» gáº·p pháº£i, ta lá»±a chá»n mÃ´ hÃ¬nh phÃ¹ há»£p (nhÆ° Logistic Regression cho Classification Problem vÃ  Linear Regression cho Regression Problem). Cá»‘ gáº¯ng cÃ i Ä‘áº·t vÃ  huáº¥n luyá»‡n mÃ¡y vá»›i lÆ°á»£ng dá»¯ liá»‡u hiá»‡n cÃ³, káº¿ tiáº¿p ta Ä‘em káº¿t quáº£ training Ä‘i thá»­ nghiá»‡m vá»›i thá»±c táº¿ vÃ¬ náº¿u nhÆ° ta Ä‘em dá»¯ liá»‡u Ä‘Ã£ training Ä‘á»ƒ test, cÃ³ thá»ƒ káº¿t quáº£ sáº½ váº«n kháº£ quan. LÃºc nÃ y náº¿u nhÆ° lÃºc nÃ y káº¿t quáº£ thu Ä‘Æ°á»£c sai lá»‡ch quÃ¡ nhiá»u, tá»›i má»©c khÃ´ng thá»ƒ cháº¥p nháº­n Ä‘Æ°á»£c. (NhÆ° tháº¿ nÃ o lÃ  khÃ´ng cháº¥p nháº­n Ä‘Æ°á»£c tuá»³ thuá»™c vÃ o yÃªu cáº§u cá»§a dá»± Ã¡n). Trong trÆ°á»ng há»£p Ä‘Ã³, nhá»¯ng giáº£i phÃ¡p sau cÃ³ thá»ƒ cÃ³ Ã­ch:

* ThÃªm dá»¯ liá»‡u vÃ o táº­p training.
* Giáº£m sá»‘ lÆ°á»£ng feature.
* TÄƒng sá»‘ lÆ°á»£ng feature.
* ThÃªm thÃ nh pháº§n Ä‘a thá»©c.
* Thay tháº¿ toÃ n bá»™ cÃ¡c feature, má»›i hÆ¡n, tá»‘t hÆ¡n. (Náº¿u nhÆ° báº¡n hiá»ƒu ráº¥t rÃµ váº¥n Ä‘á» cá»§a mÃ¬nh)
* TÄƒng giáº£m ğº. (Regularization)
* Thay Ä‘á»•i mÃ´ hÃ¬nh, giáº£i thuáº­t.

Máº·c dÃ¹ ta cÃ³ nhá»¯ng giáº£i phÃ¡p nhÆ° trÃªn, nhÆ°ng náº¿u khÃ´ng lá»±a chá»n má»™t cÃ¡ch phÃ¹ há»£p cÃ³ thá»ƒ khiáº¿n ta máº¥t thÃªm nhiá»u thÃ¡ng trá»i. Cháº³ng háº¡n mÃ´ hÃ¬nh Ä‘Ã£ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c giá»›i háº¡n, dÃ¹ cÃ³ cá»‘ gáº¯ng thÃªm nhiá»u data, káº¿t quáº£ cÅ©ng khÃ´ng tá»‘t hÆ¡n. (Cháº³ng háº¡n trong nháº­n diá»‡n chá»¯ viáº¿t tay Softmax Regression chá»‰ cÃ³ thá»ƒ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c quanh 90%, nÃªn muá»‘n mÃ´ hÃ¬nh tá»‘t hÆ¡n ta cÃ³ thá»ƒ sá»­ dá»¥ng CNN â€“ Convolution Neuron Network).

## 2. Evaluating a hypothesis:

Äá»ƒ Ä‘Ã¡nh giÃ¡ hÃ m hypothesis má»™t cÃ¡ch khÃ¡ch quan, ta cáº§n má»™t táº­p dá»¯ liá»‡u Ä‘á»™c láº­p vá»›i táº­p training. Tuy nhiÃªn thay vÃ¬ thu tháº­p dá»¯ liá»‡u má»›i sau quÃ¡ trÃ¬nh há»c vá»›i táº¥t cáº£ dá»¯ liá»‡u ta cÃ³ trÆ°á»›c Ä‘Ã³, ta chia táº­p dá»¯ liá»‡u ban Ä‘áº§u thÃ nh 2 pháº§n:

* Data Training set (táº­p dá»¯ liá»‡u sá»­ dá»¥ng Ä‘á»ƒ há»c, thÆ°á»ng chiáº¿m 70%)
* Data Test set (táº­p dá»¯ liá»‡u sá»­ dá»¥ng Ä‘á»ƒ test, thÆ°á»ng chiáº¿m 30%)

Äá»ƒ Ä‘Ã¡nh giÃ¡ sai sá»‘ cá»§a hÃ m hypothesis sau quÃ¡ trÃ¬nh há»c trÃªn táº­p dá»¯ liá»‡u kiá»ƒm thá»­, ta sá»­ dá»¥ng cost function giá»‘ng nhÆ° trÃªn táº­p training, riÃªng vá»›i Classification Problem, cost function Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn xÃ¡c suáº¥t xáº£y ra cá»§a cÃ¡c cáº·p dá»¯ liá»‡u trong táº­p training nÃªn ta sáº½ xá»­ lÃ½ khÃ¡c má»™t chÃºt.

* Vá»›i Regression Problem, tÆ°Æ¡ng tá»± nhÆ° trÃªn táº­p training (cháº³ng háº¡n trong mÃ´ hÃ¬nh Linear Regression vá»›i Least Square): 
\\[ J _{test} (\theta) = \frac {1} {2m _{test}} \sum _{i=1} ^{m _{test}} (h _{\theta} ( x _{test} ^{(i)} ) - y _{test} ^{(i)}) ^{2} \\]

* Vá»›i Classificationn Problem, sai sá»‘ lÃ  trung bÃ¬nh sá»‘ láº§n mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n sai:

<img src="/assets/content_images/ml11-01.png" alt = "" width = "80%">

\\[ J _{test} (\theta) = \frac{1}{m _{test}} \sum _{i=1} ^{m _{test}} error( h _{\theta} (x _{test} ^{(i)}), y _{test} )\\]

ÄÃ¢y lÃ  kÄ© thuáº­t cÆ¡ báº£n Ä‘á»ƒ kiá»ƒm tra xem hÃ m hypothesis cÃ³ tá»‘t hay khÃ´ng. Náº¿u khÃ´ng tá»‘t, á»Ÿ táº­p **test**, sai sá»‘ sáº½ ráº¥t lá»›n.

## 3. Model selection & training validation test sets:

Khi mÃ´ hÃ¬nh khÃ´ng Ä‘á»§ phá»©c táº¡p Ä‘á»ƒ mÃ´ táº£ Ä‘Æ°á»£c xu hÆ°á»›ng cá»§a dá»¯ liá»‡u, chÃºng ta cÃ³ thá»ƒ sáº½ cáº§n tÄƒng báº­c cho x (nÃ³i cÃ¡ch khÃ¡c lÃ  thÃªm cÃ¡c thÃ nh pháº§n \\(x^2, x^3\\) â€¦ vÃ o cÃ¡c feature x). CÃ ng nÃ¢ng báº­c cá»§a x ta cÃ ng cÃ³ mÃ´ hÃ¬nh fit dá»¯ liá»‡u trong táº­p training tá»‘t hÆ¡n, tuy nhiÃªn cÃ³ thá»ƒ khiáº¿n cho mÃ´ hÃ¬nh rÆ¡i vÃ o tÃ¬nh tráº¡ng Overfitting. DÃ¹ cÃ³ Regularization, ta cÅ©ng váº«n chÆ°a biáº¿t nÃªn chá»n ğº cho phÃ¹ há»£p. Váº­y nÃªn tÄƒng báº­c cá»§a x vÃ  chá»n ğº nhÆ° tháº¿ nÃ o cho phÃ¹ há»£p ?
Ta láº¥y vÃ­ dá»¥ vá»›i Linear Regression. Giáº£ sá»­ ta nÃ¢ng x lÃªn tá»›i báº­c 10 Ä‘Ã£ cho giÃ¡ trá»‹ cá»§a cost function trÃªn táº­p training ráº¥t nhá». 

<img src="/assets/content_images/ml11-02.png" alt = "" width = "80%">

Vá»›i má»—i báº­c ta lá»±a chá»n, sá»‘ lÆ°á»£ng vÃ  giÃ¡ trá»‹ cÃ¡c tham sá»‘ \\( \theta \\) cÅ©ng khÃ¡c. TÃ­nh sai sá»‘ trÃªn táº­p kiá»ƒm tra vá»›i cÃ¡c mÃ´ hÃ¬nh khÃ¡c nhau ta thu Ä‘Æ°á»£c :

<img src="/assets/content_images/ml11-03.png" alt = "" width = "70%">

Má»™t cÃ¡ch logic, ta sáº½ lá»±a chá»n mÃ´ hÃ¬nh cÃ³ sai sá»‘ trÃªn táº­p kiá»ƒm thá»­ nhá» nháº¥t. Cháº³ng háº¡n vá»›i báº­c = 3, ta thu Ä‘Æ°á»£c sai sá»‘ nhá» nháº¥t trÃªn táº­p test. ÄÃºng ra lÃºc nÃ y ta Ä‘em mÃ´ hÃ¬nh thu Ä‘Æ°á»£c Ä‘i á»©ng dá»¥ng pháº£i cÃ³ káº¿t quáº£ tá»‘t, nhÆ°ng báº±ng cÃ¡ch nÃ o Ä‘Ã³, dá»¯ liá»‡u thá»±c táº¿ láº¡i khÃ´ng Ä‘Æ°á»£c dá»± Ä‘oÃ¡n tá»‘t. Táº¡i sao láº¡i nhÆ° váº­y, rÃµ rÃ ng chÃºng ta Ä‘Ã£ trÃ¡nh Ä‘á»ƒ mÃ´ hÃ¬nh test trÃªn táº­p training, nhÆ°ng khi lá»±a chá»n báº­c tá»‘t nháº¥t vá»›i táº­p test, vÃ´ tÃ¬nh ta Ä‘Ã£ chá»n mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n tá»‘t chá»‰ trÃªn táº­p test. Má»™t hÃ¬nh thá»©c ta cho mÃ¡y há»c trÃªn táº­p test, nhÆ° váº­y mÃ´ hÃ¬nh nÃ y váº«n chÆ°a tá»‘t. CÃ³ láº½ ta cáº§n má»™t phÆ°Æ¡ng phÃ¡p kiá»ƒm tra hÃ m hypothesis tá»‘t hÆ¡n.
Thay vÃ¬ chia táº­p dá»¯ liá»‡u ta cÃ³ thÃ nh 2 pháº§n, giá» ta chia chÃºng thÃ nh 3 pháº§n:

* 1. Training set (DÃ¹ng cho quÃ¡ trÃ¬nh há»c, thÆ°á»ng chiáº¿m khoáº£ng 60% vá»›i (m_{train}) bá»™ training data)
* 2. Cross validation set (CV â€“ DÃ¹ng thay tháº¿ cho táº­p test á»Ÿ trÃªn, Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ khÃ¡ch quan hÆ¡n cho quÃ¡ trÃ¬nh há»c, thÆ°á»ng chiáº¿m khoáº£ng 20% vá»›i \\(m_{cv}\\) bá»™ dá»¯ liá»‡u)
* 3. Test set (Chá»‰ dÃ¹ng vá»›i má»¥c Ä‘Ã­ch test cuá»‘i cÃ¹ng, khÃ´ng dÃ¹ng Ä‘á»ƒ lá»±a chá»n mÃ´ hÃ¬nh, thÆ°á»ng chiáº¿m khoáº£ng 20% vá»›i \\(m_{test}\\) bá»™ dá»¯ liá»‡u).
CÃ¡ch tÃ­nh sai sá»‘ cho hÃ m hypothesis trÃªn tá»«ng pháº§n dá»¯ liá»‡u á»Ÿ trÃªn lÃ  nhÆ° nhau:

\\[ J _{train} (\theta) = \frac{1}{2m _{train}} \sum _{i=1} ^{m _{train}} (h _{\theta} ( x _{train} ^{(i)} ) - y _{train} ^{(i)}) ^{2} \\]

\\[ J _{cv} (\theta) = \frac{1}{2m _{cv}} \sum _{i=1} ^{m _{cv}} (h _{\theta} ( x _{cv} ^{(i)} ) - y _{cv} ^{(i)}) ^{2} \\]

\\[ J _{test} (\theta) = \frac{1}{2m _{test}} \sum _{i=1} ^{m _{test}} (h _{\theta} ( x _{test} ^{(i)} ) - y _{test} ^{(i)}) ^{2} \\]

Äáº¿n Ä‘Ã¢y, sau khi cho mÃ¡y há»c trÃªn tá»«ng mÃ´ hÃ¬nh, ta tÃ­nh sai sá»‘ cho cÃ¡c mÃ´ hÃ¬nh. LÃ m tÆ°Æ¡ng tá»± nhÆ° trÃªn, test hÃ m hypothesis vá»›i CV set vÃ  lá»±a chá»n hÃ m hypothesis vá»›i sai sá»‘ trÃªn táº­p CV lÃ  nhá» nháº¥t. Sau Ä‘Ã³ ta test láº¡i vá»›i test set.
Viá»‡c lÃ m nhÆ° trÃªn Ä‘á»ƒ trÃ¡nh hÃ m hypothesis bá»‹ bias (underfitting problem). Tuy nhiÃªn hiá»‡n nay váº«n cÃ³ nhiá»u ngÆ°á»i bá» qua viá»‡c táº¡o táº­p CV, mÃ  chá»‰ phá»¥ thuá»™c vÃ o táº­p test nhÆ°ng váº«n Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ tá»‘t (thÆ°á»ng lÃ  vÃ¬ sá»‘ lÆ°á»£ng dá»¯ liá»‡u test lá»›n nÃªn váº«n mÃ´ táº£ Ä‘Æ°á»£c xu tháº¿ cá»§a dá»¯ liá»‡u chung). Báº£n thÃ¢n tÃ´i khuyáº¿n nghá»‹ cÃ¡c báº¡n nÃªn chia táº­p dá»¯ liá»‡u thÃ nh 3 pháº§n nhÆ° trÃªn.

## 4. Diagnosis â€“ bias & variance:

Káº¿t quáº£ thu Ä‘Æ°á»£c tá»« hÃ m hypothesis trÃªn táº­p training, CV hay test khÃ´ng tá»‘t Ä‘á»u bá»Ÿi vÃ¬ má»™t trong hai váº¥n Ä‘á» ta Ä‘Ã£ nÃ³i trong bÃ i trÆ°á»›c :

* High bias: under fitting problem
* High variance: over fitting problem

Underfitting: \\(d = 1\\)

<img src="/assets/content_images/ml11-04.png" alt = "" width = "60%">

Overfitting: 

<img src="/assets/content_images/ml11-05.png" alt = "" width = "60%">

Khi báº­c cá»§a model tÄƒng, ta sáº½ giáº£m thiá»ƒu Ä‘Æ°á»£c kháº£ nÄƒng vÆ°á»›ng vÃ o High bias nhÆ°ng dá»… vÆ°á»›ng vÃ o High variance. Vá»›i \\(d\\) lÃ  báº­c cá»§a model nhÆ° Ä‘Ã£ Ä‘á»‹nh nghÄ©a á»Ÿ trÃªn, ta váº½ Ä‘á»“ thá»‹ xem sai sá»‘ trÃªn táº­p training vÃ  CV thay Ä‘á»•i nhÆ° tháº¿ nÃ o khi \\(d\\) thay Ä‘á»•i.

<img src="/assets/content_images/ml11-06.png" alt = "" width = "60%">

NhÆ° trÃªn Ä‘á»“ thá»‹, táº¡i Ä‘iá»ƒm \\(d = 2\\) thÃ¬ giÃ¡ trá»‹ cá»§a \\(J _{cv}\\) lÃ  nhá» nháº¥t. Vá»›i \\(d\\) quÃ¡ nhá», ta sáº½ vÆ°á»›ng vÃ o high bias problem (sai sá»‘ trÃªn cáº£ táº­p training vÃ  CV Ä‘á»u lá»›n), cÃ²n vá»›i \\(d\\) quÃ¡ lá»›n sáº½ bá»‹ high variance problem (sai sá»‘ trÃªn táº­p training nhá» nhÆ°ng trÃªn táº­p CV láº¡i lá»›n).
Trong pháº§n tiáº¿p theo chÃºng ta sáº½ tiáº¿p tá»¥c tÃ¬m hiá»ƒu cÃ¡ch Ä‘á»ƒ lá»±a chá»n \\( \lambda \\) cho pháº§n **Regularization**. Cáº£m Æ¡n cÃ¡c báº¡n Ä‘Ã£ theo dÃµi vÃ  háº¹n gáº·p láº¡i trong bÃ i viáº¿t tiáº¿p theo.